<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>DeepSeek Streaming API Documentation</title>
    <link href="/css/tailwind.css" rel="stylesheet">
    <style>
        .code-block {
            background: #1a1a1a;
            border: 1px solid #333;
            border-radius: 8px;
            padding: 1rem;
            font-family: 'Monaco', 'Menlo', monospace;
            font-size: 0.875rem;
            overflow-x: auto;
        }
        .endpoint-badge {
            display: inline-block;
            padding: 0.25rem 0.5rem;
            border-radius: 4px;
            font-size: 0.75rem;
            font-weight: bold;
        }
        .post-badge { background: #059669; color: white; }
        .get-badge { background: #0ea5e9; color: white; }
    </style>
</head>
<body class="bg-gray-900 text-white min-h-screen">
    <!-- Navigation -->
    <nav class="bg-gray-800 border-b border-gray-700 px-6 py-4">
        <div class="flex items-center justify-between">
            <div class="flex items-center space-x-4">
                <h1 class="text-xl font-bold">DeepSeek API Documentation</h1>
                <div class="flex space-x-6">
                    <a href="/" class="text-gray-300 hover:text-white">Generator</a>
                    <a href="/streaming-demo.html" class="text-gray-300 hover:text-white">Streaming Demo</a>
                    <a href="/chat.html" class="text-gray-300 hover:text-white">Chat</a>
                    <a href="/streaming-api-docs.html" class="text-blue-400 font-medium">API Docs</a>
                </div>
            </div>
        </div>
    </nav>

    <div class="container mx-auto px-4 py-8 max-w-4xl">
        <!-- Header -->
        <div class="mb-8">
            <h1 class="text-3xl font-bold mb-4">Real-Time Streaming API</h1>
            <p class="text-gray-400 text-lg">Comprehensive documentation for DeepSeek AI streaming integration</p>
        </div>

        <!-- Overview -->
        <section class="bg-gray-800 rounded-lg p-6 mb-8">
            <h2 class="text-2xl font-semibold mb-4">Overview</h2>
            <p class="text-gray-300 mb-4">
                The DeepSeek AI Platform provides real-time streaming chat responses using Server-Sent Events (SSE). 
                This allows for token-by-token delivery of AI responses, creating a natural conversational experience.
            </p>
            <div class="grid grid-cols-1 md:grid-cols-3 gap-4">
                <div class="bg-gray-700 p-4 rounded">
                    <h3 class="font-semibold mb-2">Technology</h3>
                    <p class="text-sm text-gray-400">Server-Sent Events (SSE) for real-time streaming</p>
                </div>
                <div class="bg-gray-700 p-4 rounded">
                    <h3 class="font-semibold mb-2">Protocol</h3>
                    <p class="text-sm text-gray-400">HTTP/1.1 with streaming response bodies</p>
                </div>
                <div class="bg-gray-700 p-4 rounded">
                    <h3 class="font-semibold mb-2">Format</h3>
                    <p class="text-sm text-gray-400">JSON data wrapped in SSE format</p>
                </div>
            </div>
        </section>

        <!-- Streaming Endpoint -->
        <section class="bg-gray-800 rounded-lg p-6 mb-8">
            <h2 class="text-2xl font-semibold mb-4">Streaming Chat Endpoint</h2>
            
            <div class="mb-6">
                <div class="flex items-center space-x-3 mb-4">
                    <span class="endpoint-badge post-badge">POST</span>
                    <code class="text-blue-400">/api/chat/stream</code>
                </div>
                <p class="text-gray-400">Stream real-time chat responses token-by-token.</p>
            </div>

            <!-- Request Format -->
            <div class="mb-6">
                <h3 class="text-lg font-semibold mb-3">Request Body</h3>
                <div class="code-block">
                    <pre><code>{
  "messages": [
    {
      "role": "user",
      "content": "Your message here"
    },
    {
      "role": "assistant", 
      "content": "Previous assistant response"
    },
    {
      "role": "user",
      "content": "Follow-up message"
    }
  ]
}</code></pre>
                </div>
            </div>

            <!-- Response Format -->
            <div class="mb-6">
                <h3 class="text-lg font-semibold mb-3">Response Format</h3>
                <p class="text-gray-400 mb-3">The endpoint returns Server-Sent Events with the following data formats:</p>
                
                <h4 class="font-medium mb-2">Token Response</h4>
                <div class="code-block mb-4">
                    <pre><code>data: {"token": "Hello"}</code></pre>
                </div>

                <h4 class="font-medium mb-2">Completion Response</h4>
                <div class="code-block mb-4">
                    <pre><code>data: {"complete": true, "content": "Full response content"}</code></pre>
                </div>

                <h4 class="font-medium mb-2">Error Response</h4>
                <div class="code-block">
                    <pre><code>data: {"error": "Error message description"}</code></pre>
                </div>
            </div>

            <!-- Headers -->
            <div class="mb-6">
                <h3 class="text-lg font-semibold mb-3">Response Headers</h3>
                <div class="code-block">
                    <pre><code>Content-Type: text/plain
Cache-Control: no-cache
Connection: keep-alive
Access-Control-Allow-Origin: *</code></pre>
                </div>
            </div>
        </section>

        <!-- JavaScript Implementation -->
        <section class="bg-gray-800 rounded-lg p-6 mb-8">
            <h2 class="text-2xl font-semibold mb-4">Frontend Implementation</h2>
            
            <h3 class="text-lg font-semibold mb-3">Basic Streaming Client</h3>
            <div class="code-block mb-6">
                <pre><code>async function streamChatResponse(messages, onToken, onComplete, onError) {
  try {
    const response = await fetch('/api/chat/stream', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({ messages })
    });

    if (!response.ok) {
      throw new Error(`HTTP ${response.status}: ${response.statusText}`);
    }

    const reader = response.body.getReader();
    const decoder = new TextDecoder('utf-8');
    let buffer = '';

    while (true) {
      const { done, value } = await reader.read();
      if (done) break;

      buffer += decoder.decode(value, { stream: true });
      const lines = buffer.split('\n');
      
      for (let i = 0; i < lines.length - 1; i++) {
        const line = lines[i].trim();
        if (line.startsWith('data: ')) {
          try {
            const data = JSON.parse(line.slice(6));
            
            if (data.error) {
              onError(new Error(data.error));
              return;
            }
            
            if (data.token) {
              onToken(data.token);
            }
            
            if (data.complete) {
              onComplete(data.content);
              return;
            }
          } catch (parseError) {
            console.warn('Failed to parse streaming data:', parseError);
          }
        }
      }
      
      buffer = lines[lines.length - 1];
    }
  } catch (error) {
    onError(error);
  }
}</code></pre>
            </div>

            <h3 class="text-lg font-semibold mb-3">Usage Example</h3>
            <div class="code-block">
                <pre><code>const messages = [
  { role: 'user', content: 'Explain quantum computing' }
];

await streamChatResponse(
  messages,
  (token) => {
    // Update UI with each token
    responseElement.textContent += token;
  },
  (fullContent) => {
    // Handle completion
    console.log('Complete response:', fullContent);
  },
  (error) => {
    // Handle errors
    console.error('Streaming error:', error);
  }
);</code></pre>
            </div>
        </section>

        <!-- Other Endpoints -->
        <section class="bg-gray-800 rounded-lg p-6 mb-8">
            <h2 class="text-2xl font-semibold mb-4">Additional Endpoints</h2>
            
            <div class="space-y-6">
                <!-- Generate Prompt -->
                <div class="border-l-4 border-blue-500 pl-4">
                    <div class="flex items-center space-x-3 mb-2">
                        <span class="endpoint-badge post-badge">POST</span>
                        <code class="text-blue-400">/api/generate-prompt</code>
                    </div>
                    <p class="text-gray-400 text-sm">Generate optimized prompts with RAG context integration.</p>
                </div>

                <!-- DeepSeek Stats -->
                <div class="border-l-4 border-green-500 pl-4">
                    <div class="flex items-center space-x-3 mb-2">
                        <span class="endpoint-badge get-badge">GET</span>
                        <code class="text-blue-400">/api/deepseek/stats</code>
                    </div>
                    <p class="text-gray-400 text-sm">Get DeepSeek service statistics and configuration status.</p>
                </div>

                <!-- Chat Continue -->
                <div class="border-l-4 border-purple-500 pl-4">
                    <div class="flex items-center space-x-3 mb-2">
                        <span class="endpoint-badge post-badge">POST</span>
                        <code class="text-blue-400">/api/chat/continue</code>
                    </div>
                    <p class="text-gray-400 text-sm">Continue multi-turn conversations with session management.</p>
                </div>
            </div>
        </section>

        <!-- Error Handling -->
        <section class="bg-gray-800 rounded-lg p-6 mb-8">
            <h2 class="text-2xl font-semibold mb-4">Error Handling</h2>
            
            <div class="space-y-4">
                <div class="bg-red-900/20 border border-red-500/30 rounded p-4">
                    <h3 class="font-semibold text-red-400 mb-2">Stream Interruption</h3>
                    <p class="text-gray-300 text-sm">Always handle stream interruptions gracefully and provide user feedback.</p>
                </div>

                <div class="bg-yellow-900/20 border border-yellow-500/30 rounded p-4">
                    <h3 class="font-semibold text-yellow-400 mb-2">Network Errors</h3>
                    <p class="text-gray-300 text-sm">Implement retry logic for network failures with exponential backoff.</p>
                </div>

                <div class="bg-blue-900/20 border border-blue-500/30 rounded p-4">
                    <h3 class="font-semibold text-blue-400 mb-2">Rate Limiting</h3>
                    <p class="text-gray-300 text-sm">Respect rate limits and implement appropriate queuing mechanisms.</p>
                </div>
            </div>
        </section>

        <!-- Integration Notes -->
        <section class="bg-gray-800 rounded-lg p-6">
            <h2 class="text-2xl font-semibold mb-4">Integration Notes</h2>
            
            <div class="grid grid-cols-1 md:grid-cols-2 gap-6">
                <div>
                    <h3 class="font-semibold mb-3">Best Practices</h3>
                    <ul class="text-gray-400 space-y-2 text-sm">
                        <li>• Always handle stream cancellation</li>
                        <li>• Implement proper error boundaries</li>
                        <li>• Use appropriate timeouts</li>
                        <li>• Buffer tokens for smooth display</li>
                        <li>• Provide visual feedback during streaming</li>
                    </ul>
                </div>
                <div>
                    <h3 class="font-semibold mb-3">Performance Tips</h3>
                    <ul class="text-gray-400 space-y-2 text-sm">
                        <li>• Debounce UI updates for high-frequency tokens</li>
                        <li>• Use virtual scrolling for long responses</li>
                        <li>• Implement proper memory cleanup</li>
                        <li>• Monitor connection health</li>
                        <li>• Cache conversation history locally</li>
                    </ul>
                </div>
            </div>
        </section>
    </div>
</body>
</html>